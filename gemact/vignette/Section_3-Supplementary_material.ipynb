{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary material on Section 3\n",
    "\n",
    "**We remark that the execution of this script takes several hours, due to the computing time measurement which runs several experiments.**\n",
    "\n",
    "This code block allows to replicate replicate Section 3.6 Comparison of the methods for computing the aggregate loss distribution and Section 3.7. Comparison with aggregate FFT implementation [manuscript](https://arxiv.org/abs/2303.01129) describing the usage and the design of the GEMAct package.\n",
    "\n",
    "This vignette is relative to the version 1.2.1 of the GEMAct software.\n",
    "\n",
    "We compared our computation with the version 0.9.3 of the software aggregate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install gemact==1.2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install aggregate==0.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from gemact.lossmodel import Severity, Frequency, LossModel, PolicyStructure, Layer\n",
    "from gemact.calculators import LossModelCalculator as Calculator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit as timeit\n",
    "from aggregate import build, qd\n",
    "\n",
    "# script parameters\n",
    "# local path to save\n",
    "localpath = ''\n",
    "explort_flag = True\n",
    "\n",
    "# severity parameters\n",
    "mu = 84541.68  # target mean lognorm\n",
    "sigma = 177728.3  # target std lognorm\n",
    "\n",
    "a = 1 + (sigma / mu) ** 2\n",
    "shape = np.sqrt(np.log(a))\n",
    "scale = mu / np.sqrt(a)\n",
    "\n",
    "sev_par = {'scale': scale, 'shape':shape}\n",
    "sev_dist_name = 'lognormal'\n",
    "freq_par = {'mu': 3}\n",
    "freq_dist_name = 'poisson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.6 Comparison of the methods for computing the aggregate loss distribution\n",
    "\n",
    "The parametric assumptions are taken from examples in Parodi, P. (2014). Pricing in general insurance (first ed.), pag. 262-266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# timeit parameters. Number of repetitions for computation time.\n",
    "repetitions = 7 # numer of times the experiment is repeated\n",
    "number = 100 # number of times the function is executed in a experiment.\n",
    "\n",
    "# policystructure parmateres\n",
    "deductible = 10000\n",
    "cover = float('inf')\n",
    "\n",
    "n_sev_nodes = [2**14, 2**16, 2**18]\n",
    "n_sev_nodes_str = ['2**14', '2**16', '2**18']\n",
    "n_aggr_nodes =  [2**14, 2**16, 2**18]\n",
    "discr_step = [50, 100, 200, 400]\n",
    "n_sim_mc = [2**14, 2**16, 2**18, 2**20]\n",
    "n_sim_mc_str = ['2**14', '2**16', '2**18', '2**20'] \n",
    "\n",
    "discr_methods = ['massdispersal']\n",
    "calculation_methods = [\n",
    "    'fast_fourier_transform',\n",
    "    'panjer_recursion'\n",
    "]\n",
    "calculation_methods_abbr = ['fft', 'recursion']\n",
    "\n",
    "outputtxt = []\n",
    "\n",
    "sev = Severity(par=sev_par, dist=sev_dist_name)\n",
    "freq = Frequency(dist=freq_dist_name, par=freq_par, threshold=deductible)\n",
    "pstr = PolicyStructure(layers=Layer(deductible=deductible, cover=cover))\n",
    "\n",
    "calc_true_values_flag = True\n",
    "for j in range(len(calculation_methods)):\n",
    "    for i in range(len(n_sev_nodes)):\n",
    "        print('n_sev_nodes:' + str(n_sev_nodes[i]))\n",
    "        for k in range(len(discr_step)):\n",
    "\n",
    "            print('discr_step:' + str(discr_step[k]))\n",
    "            sevdict = sev.discretize(\n",
    "            discr_method=discr_methods[0],\n",
    "            n_discr_nodes=n_sev_nodes[i],\n",
    "            discr_step=discr_step[k],\n",
    "            deductible=deductible)\n",
    "\n",
    "            lm = LossModel(\n",
    "                severity=sev,\n",
    "                frequency=freq,\n",
    "                policystructure=pstr,\n",
    "                aggr_loss_dist_method=calculation_methods_abbr[j],\n",
    "                n_aggr_dist_nodes=n_aggr_nodes[i],\n",
    "                n_sev_discr_nodes=n_sev_nodes[i],\n",
    "                sev_discr_step=discr_step[k],\n",
    "                sev_discr_method=discr_methods[0],\n",
    "                tilt=True\n",
    "                )\n",
    "            \n",
    "            if calc_true_values_flag:\n",
    "                txt = [\n",
    "                    'True Value & &',\n",
    "                    \"{:.1f}\".format(lm.mean(use_dist=False)),\n",
    "                    '& ', \"{:.5f}\".format(lm.coeff_variation(use_dist=False)),\n",
    "                    '& ', \"{:.5f}\".format(lm.skewness(use_dist=False)),\n",
    "                    '\\\\\\\\'\n",
    "                    ]\n",
    "                outputtxt.append(' '.join(txt))\n",
    "                calc_true_values_flag = False\n",
    "\n",
    "            vals = [\n",
    "                lm.mean(use_dist=True) / lm.mean(use_dist=False) - 1,\n",
    "                lm.coeff_variation(use_dist=True) / lm.coeff_variation(use_dist=False) - 1,\n",
    "                lm.skewness(use_dist=True) / lm.skewness(use_dist=False) - 1\n",
    "            ]\n",
    "            txt = [\"{:.5e}\".format(x) for x in vals]\n",
    "            \n",
    "            if calculation_methods[j] == 'fast_fourier_transform':\n",
    "                stmt = \"Calculator.\" + calculation_methods[j]+\"(\" \\\n",
    "                    \"frequency=freq,\" \\\n",
    "                    \"severity=sevdict,\" \\\n",
    "                    \"discr_step=\" + str(discr_step[k]) +\",\" \\\n",
    "                    \"tilt=True,\" \\\n",
    "                    \"tilt_value=20/\"+ str(n_aggr_nodes[i]) +\",\" \\\n",
    "                    \"n_aggr_dist_nodes=\" + str(n_aggr_nodes[i]) + \"\" \\\n",
    "                    \")\"\n",
    "            else:\n",
    "                stmt = \"Calculator.\" + calculation_methods[j]+\"(\" \\\n",
    "                    \"frequency=freq,\" \\\n",
    "                    \"severity=sevdict,\" \\\n",
    "                    \"discr_step=\" + str(discr_step[k]) +\",\" \\\n",
    "                    \"n_aggr_dist_nodes=\" + str(n_aggr_nodes[i]) + \"\" \\\n",
    "                    \")\"\n",
    "            out = timeit.repeat(stmt,\n",
    "                        repeat=repetitions,\n",
    "                        number=number,\n",
    "                        globals=locals())\n",
    "            txt.insert(0, str(round(np.min(out) / number, 5)))\n",
    "            txt.insert(0, str(calculation_methods_abbr[j]) +' (h = ' + str(discr_step[k]) + ', m = '+ str(n_sev_nodes_str[i]) + ')')\n",
    "            outputtxt.append('& '.join(txt) + '\\\\\\\\')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "calc_true_values_flag = False\n",
    "random_state = 11\n",
    "for k in range(len(n_sim_mc)):\n",
    "    lm = LossModel(\n",
    "        severity=sev,\n",
    "        frequency=freq,\n",
    "        policystructure=pstr,\n",
    "        aggr_loss_dist_method='mc',\n",
    "        n_sim=n_sim_mc[k],\n",
    "        random_state=random_state\n",
    "        )\n",
    "    if calc_true_values_flag:\n",
    "        txt = [\n",
    "            'True Value & &',\n",
    "            \"{:.1f}\".format(lm.mean(use_dist=False)),\n",
    "            '& ', \"{:.5f}\".format(lm.coeff_variation(use_dist=False)),\n",
    "            '& ', \"{:.5f}\".format(lm.skewness(use_dist=False)),\n",
    "            '\\\\\\\\'\n",
    "            ]\n",
    "        outputtxt.append(' '.join(txt))\n",
    "        calc_true_values_flag = False\n",
    "    \n",
    "    vals = [\n",
    "        lm.mean(use_dist=True) / lm.mean(use_dist=False) - 1,\n",
    "        lm.coeff_variation(use_dist=True) / lm.coeff_variation(use_dist=False) - 1,\n",
    "        lm.skewness(use_dist=True) / lm.skewness(use_dist=False) - 1\n",
    "        ]\n",
    "    txt = [\"{:.5e}\".format(x) for x in vals]\n",
    "\n",
    "    stmt = \"Calculator.mc_simulation(\" \\\n",
    "               \"severity=sev,\" \\\n",
    "               \"frequency=freq,\" \\\n",
    "               \"n_sim=\" + str(n_sim_mc[k]) + \",\" \\\n",
    "               \"random_state=\" + str(random_state) + \",\" \\\n",
    "               \"cover=float('inf'),\" \\\n",
    "               \"deductible=\" + str(deductible) + \",\" \\\n",
    "               \")\"\n",
    "    out = timeit.repeat(stmt,\n",
    "                repeat=repetitions,\n",
    "                number=number,\n",
    "                globals=locals())\n",
    "    txt.insert(0, str(round(np.min(out) / number, 4)))\n",
    "    txt.insert(0, 'MC (' + str(n_sim_mc_str[k]) + ' sim.)')\n",
    "    outputtxt.append('& '.join(txt) + '\\\\\\\\')\n",
    "\n",
    "\n",
    "# export results\n",
    "if explort_flag:\n",
    "    pd.DataFrame(data = outputtxt, columns=['text']).to_csv(localpath + 'aggr_dist_method_comparison.txt', index=False)\n",
    "    print('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.7. Comparison with aggregate FFT implementation\n",
    "\n",
    "The parametric assumptions and contract specifications taken from examples in Parodi, P. (2014). Pricing in general insurance (first ed.), pag. 262-266."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sev = Severity(par=sev_par, dist=sev_dist_name)\n",
    "# frequency and policystructure specified below.\n",
    "outputtxt = []\n",
    "\n",
    "n_nodes = 2**22\n",
    "power_nodes = int(np.log2(n_nodes))\n",
    "discr_step = 500\n",
    "deductible = 10000\n",
    "cover = 1000000\n",
    "aggr_cover = 1000000\n",
    "aggr_deductible = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No individual, no aggregate conditions\n",
    "\n",
    "deductible = 0, cover = inf, aggr. cover = inf, aggr. deductible = 0, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "agg_nr = build(\n",
    "    'agg noreins 3 claims sev lognorm 84541.68 cv 2.1022565437545127 poisson',\n",
    "    log2=power_nodes,\n",
    "    padding=0,\n",
    "    bs=discr_step\n",
    "    )\n",
    "\n",
    "stmt = \"build('agg noreins 3 claims sev lognorm 84541.68 cv 2.1022565437545127 poisson',\" \\\n",
    "            \"log2=\" +str(power_nodes) + \",\" \\\n",
    "            \"padding=0,\" \\\n",
    "            \"bs=\" + str(discr_step)  + \",\" \\\n",
    "            \")\"\n",
    "outagg = timeit.repeat(stmt,\n",
    "            repeat=repetitions,\n",
    "            number=number,\n",
    "            globals=locals())\n",
    "\n",
    "freq = Frequency(dist=freq_dist_name, par=freq_par, threshold=0)\n",
    "pstr = PolicyStructure()\n",
    "lm = LossModel(\n",
    "    frequency=freq,\n",
    "    severity=sev,\n",
    "    policystructure=pstr,\n",
    "    aggr_loss_dist_method='fft',\n",
    "    n_aggr_dist_nodes=n_nodes,\n",
    "    sev_discr_step=discr_step,\n",
    "    sev_discr_method='massdispersal'\n",
    ")\n",
    "stmt = \"LossModel(\"\\\n",
    "    \"frequency=freq,\"\\\n",
    "    \"severity=sev,\"\\\n",
    "    \"policystructure=pstr,\"\\\n",
    "    \"aggr_loss_dist_method='fft',\"\\\n",
    "    \"n_aggr_dist_nodes=\" + str(n_nodes) + \",\" \\\n",
    "    \"sev_discr_step=\"+ str(discr_step) + \",\" \\\n",
    "    \"sev_discr_method='massdispersal'\"\\\n",
    "    \")\"\n",
    "outgem = timeit.repeat(stmt,\n",
    "            repeat=repetitions,\n",
    "            number=number,\n",
    "            globals=locals())\n",
    "\n",
    "txt = [\n",
    "    ' & Reference Value & &',\n",
    "    \"{:.1f}\".format(lm.mean(use_dist=False)),\n",
    "    '& ', \"{:.5f}\".format(lm.coeff_variation(use_dist=False)),\n",
    "    '& ', \"{:.5f}\".format(lm.skewness(use_dist=False)),\n",
    "    '\\\\\\\\'\n",
    "    ]\n",
    "outputtxt.append(' '.join(txt))\n",
    "\n",
    "txt = [\n",
    "    ' & gemact &',\n",
    "    str(round(np.min(outgem) / number, 4)) + '& ',\n",
    "    \"{:.1f}\".format(lm.mean(use_dist=True)),\n",
    "    '& ', \"{:.5f}\".format(lm.coeff_variation(use_dist=True)),\n",
    "    '& ', \"{:.5f}\".format(lm.skewness(use_dist=True)),\n",
    "    '\\\\\\\\'\n",
    "    ]\n",
    "outputtxt.append(' '.join(txt))\n",
    "\n",
    "txt = [\n",
    "    ' & aggregate &',\n",
    "    str(round(np.min(outagg) / number, 4)) + '& ',\n",
    "    \"{:.1f}\".format(agg_nr.est_m),\n",
    "    '& ', \"{:.5f}\".format(agg_nr.est_cv),\n",
    "    '& ', \"{:.5f}\".format(agg_nr.est_skew),\n",
    "    '\\\\\\\\'\n",
    "    ]\n",
    "outputtxt.append(' '.join(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XL no aggregate conditions\n",
    "\n",
    "deductible = 10000, cover = 1000000, aggr. deductible = 0, aggr. cover = inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "agg_xl = build(\n",
    "    'agg noreins 3 claims 1000000 xs 10000 sev lognorm 84541.68 cv 2.1022565437545127 poisson',\n",
    "    log2=power_nodes,\n",
    "    padding=0,\n",
    "    bs=discr_step\n",
    "    )\n",
    "agg_xl.describe\n",
    "\n",
    "stmt = \"build('agg noreins 3 claims 1000000 xs 10000 sev lognorm 84541.68 cv 2.1022565437545127 poisson',\" \\\n",
    "            \"log2=\" +str(power_nodes) + \",\" \\\n",
    "            \"padding=0,\" \\\n",
    "            \"bs=\" + str(discr_step)  + \",\" \\\n",
    "            \")\"\n",
    "outagg = timeit.repeat(stmt,\n",
    "            repeat=repetitions,\n",
    "            number=number,\n",
    "            globals=locals())\n",
    "\n",
    "pstr = PolicyStructure(\n",
    "    layers=Layer(\n",
    "        deductible=deductible,\n",
    "        cover=cover\n",
    "    )\n",
    ")\n",
    "\n",
    "freq = Frequency(dist=freq_dist_name, par=freq_par, threshold=deductible)\n",
    "lm_xl = LossModel(\n",
    "    frequency=freq,\n",
    "    severity=sev,\n",
    "    policystructure=pstr,\n",
    "    aggr_loss_dist_method='fft',\n",
    "    n_aggr_dist_nodes=n_nodes,\n",
    "    sev_discr_method='massdispersal'\n",
    ")\n",
    "\n",
    "stmt = \"LossModel(\"\\\n",
    "    \"frequency=freq,\"\\\n",
    "    \"severity=sev,\"\\\n",
    "    \"policystructure=pstr,\"\\\n",
    "    \"aggr_loss_dist_method='fft',\"\\\n",
    "    \"n_aggr_dist_nodes=\" + str(n_nodes) + \",\" \\\n",
    "    \"sev_discr_method='massdispersal'\"\\\n",
    "    \")\"\n",
    "outgem = timeit.repeat(stmt,\n",
    "            repeat=repetitions,\n",
    "            number=number,\n",
    "            globals=locals())\n",
    "txt = [\n",
    "    ' & Reference Value & &',\n",
    "    \"{:.1f}\".format(lm_xl.mean(use_dist=False)),\n",
    "    '& ', \"{:.5f}\".format(lm_xl.coeff_variation(use_dist=False)),\n",
    "    '& ', \"{:.5f}\".format(lm_xl.skewness(use_dist=False)),\n",
    "    '\\\\\\\\'\n",
    "    ]\n",
    "outputtxt.append(' '.join(txt))\n",
    "\n",
    "txt = [\n",
    "    ' & gemact &',\n",
    "    str(round(np.min(outgem) / number, 4)) + '& ',\n",
    "    \"{:.1f}\".format(lm_xl.mean(use_dist=True)),\n",
    "    '& ', \"{:.5f}\".format(lm_xl.coeff_variation(use_dist=True)),\n",
    "    '& ', \"{:.5f}\".format(lm_xl.skewness(use_dist=True)),\n",
    "    '\\\\\\\\'\n",
    "    ]\n",
    "outputtxt.append(' '.join(txt))\n",
    "\n",
    "\n",
    "txt = [\n",
    "    ' & aggregate &',\n",
    "    str(round(np.min(outagg) / number, 4)) + '& ',\n",
    "    \"{:.1f}\".format(agg_xl.est_m),\n",
    "    '& ', \"{:.5f}\".format(agg_xl.est_cv),\n",
    "    '& ', \"{:.5f}\".format(agg_xl.est_skew),\n",
    "    '\\\\\\\\'\n",
    "    ]\n",
    "outputtxt.append(' '.join(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XL aggregate conditions only, i.e. SL\n",
    "\n",
    "deductible = 0, cover = inf, aggr. deductible = 50000, aggr. cover = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "agg_sl = build(\n",
    "    'agg experiment 3 claims sev lognorm 84541.68 cv 2.1022565437545127 poisson aggregate ceded to 1000000 xs 50000',\n",
    "    log2=power_nodes,\n",
    "    padding=0,\n",
    "    bs=discr_step\n",
    "    )\n",
    "agg_sl.describe\n",
    "\n",
    "stmt = \"build('agg experiment 3 claims sev lognorm 84541.68 cv 2.1022565437545127 poisson aggregate ceded to 1000000 xs 50000',\" \\\n",
    "            \"log2=\" +str(power_nodes) + \",\" \\\n",
    "            \"padding=0,\" \\\n",
    "            \"bs=\" + str(discr_step)  + \",\" \\\n",
    "            \")\"\n",
    "outagg = timeit.repeat(stmt,\n",
    "            repeat=repetitions,\n",
    "            number=number,\n",
    "            globals=locals())\n",
    "\n",
    "freq = Frequency(dist=freq_dist_name, par=freq_par, threshold=0)\n",
    "pstr = PolicyStructure(\n",
    "    layers=Layer(\n",
    "        deductible = 0,\n",
    "        cover = float('inf'),\n",
    "        aggr_deductible = aggr_deductible,\n",
    "        aggr_cover = aggr_cover\n",
    "    )\n",
    ")\n",
    "\n",
    "lm_sl = LossModel(\n",
    "    frequency=freq,\n",
    "    severity=sev,\n",
    "    policystructure=pstr,\n",
    "    aggr_loss_dist_method='fft',\n",
    "    n_aggr_dist_nodes=n_nodes,\n",
    "    sev_discr_step=discr_step,\n",
    "    sev_discr_method='massdispersal'\n",
    ")\n",
    "\n",
    "stmt = \"LossModel(\"\\\n",
    "    \"frequency=freq,\"\\\n",
    "    \"severity=sev,\"\\\n",
    "    \"policystructure=pstr,\"\\\n",
    "    \"aggr_loss_dist_method='fft',\"\\\n",
    "    \"n_aggr_dist_nodes=\" + str(n_nodes) + \",\" \\\n",
    "    \"sev_discr_step=\"+ str(discr_step) + \",\" \\\n",
    "    \"sev_discr_method='massdispersal'\"\\\n",
    "    \")\"\n",
    "outgem = timeit.repeat(stmt,\n",
    "            repeat=repetitions,\n",
    "            number=number,\n",
    "            globals=locals())\n",
    "\n",
    "txt = [' & Reference Value & - & - & -\\\\\\\\']\n",
    "outputtxt.append(' '.join(txt))\n",
    "\n",
    "txt = [\n",
    "    ' & gemact &',\n",
    "    str(round(np.min(outgem) / number, 4)) + '& ',\n",
    "    \"{:.1f}\".format(lm_sl.mean(use_dist=True)),\n",
    "    '& ', \"{:.5f}\".format(lm_sl.coeff_variation(use_dist=True)),\n",
    "    '& ', \"{:.5f}\".format(lm_sl.skewness(use_dist=True)),\n",
    "    '\\\\\\\\'\n",
    "    ]\n",
    "outputtxt.append(' '.join(txt))\n",
    "\n",
    "txt = [\n",
    "    ' & aggregate &',\n",
    "    str(round(np.min(outagg) / number, 4)) + '& ',\n",
    "    \"{:.1f}\".format(agg_sl.est_m),\n",
    "    '& ', \"{:.5f}\".format(agg_sl.est_cv),\n",
    "    '& ', \"{:.5f}\".format(agg_sl.est_skew),\n",
    "    '\\\\\\\\'\n",
    "    ]\n",
    "outputtxt.append(' '.join(txt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XL with aggregate conditions (XL + SL)\n",
    "\n",
    "deductible = 10000, cover = 1000000, aggr. deductible = 50000, aggr. cover = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "agg_xlsl = build('agg experiment 3 claims 1000000 xs 10000 sev lognorm 84541.68 cv 2.1022565437545127 poisson aggregate ceded to 1000000 xs 50000',\n",
    "        log2=power_nodes,\n",
    "        padding=0,\n",
    "        bs=discr_step)\n",
    "agg_xlsl.describe\n",
    "\n",
    "stmt = \"build('agg experiment 3 claims 1000000 xs 10000 sev lognorm 84541.68 cv 2.1022565437545127 poisson aggregate ceded to 1000000 xs 50000',\" \\\n",
    "            \"log2=\" +str(power_nodes) + \",\" \\\n",
    "            \"padding=0,\" \\\n",
    "            \"bs=\" + str(discr_step)  + \",\" \\\n",
    "            \")\"\n",
    "outagg = timeit.repeat(stmt,\n",
    "            repeat=repetitions,\n",
    "            number=number,\n",
    "            globals=locals())\n",
    "\n",
    "pstr = PolicyStructure(\n",
    "    layers=Layer(\n",
    "        deductible = deductible,\n",
    "        cover = cover,\n",
    "        aggr_deductible = aggr_deductible,\n",
    "        aggr_cover = aggr_cover\n",
    "    )\n",
    ")\n",
    "freq = Frequency(dist=freq_dist_name, par=freq_par, threshold=deductible)\n",
    "lm_xlsl = LossModel(\n",
    "    frequency=freq,\n",
    "    severity=sev,\n",
    "    policystructure=pstr,\n",
    "    aggr_loss_dist_method='fft',\n",
    "    n_aggr_dist_nodes=n_nodes,\n",
    "    sev_discr_method='massdispersal'\n",
    ")\n",
    "\n",
    "stmt = \"LossModel(\"\\\n",
    "    \"frequency=freq,\"\\\n",
    "    \"severity=sev,\"\\\n",
    "    \"policystructure=pstr,\"\\\n",
    "    \"aggr_loss_dist_method='fft',\"\\\n",
    "    \"n_aggr_dist_nodes=\" + str(n_nodes) + \",\" \\\n",
    "    \"sev_discr_method='massdispersal'\"\\\n",
    "    \")\"\n",
    "outgem = timeit.repeat(stmt,\n",
    "            repeat=repetitions,\n",
    "            number=number,\n",
    "            globals=locals())\n",
    "\n",
    "txt = [' & Reference Value & - & - & -\\\\\\\\']\n",
    "outputtxt.append(' '.join(txt))\n",
    "\n",
    "txt = [\n",
    "    ' & gemact &',\n",
    "    str(round(np.min(outgem) / number, 4)) + '& ',\n",
    "    \"{:.1f}\".format(lm_xlsl.mean(use_dist=True)),\n",
    "    '& ', \"{:.5f}\".format(lm_xlsl.coeff_variation(use_dist=True)),\n",
    "    '& ', \"{:.5f}\".format(lm_xlsl.skewness(use_dist=True)),\n",
    "    '\\\\\\\\'\n",
    "    ]\n",
    "outputtxt.append(' '.join(txt))\n",
    "\n",
    "txt = [\n",
    "    ' & aggregate &',\n",
    "    str(round(np.min(outagg) / number, 4)) + '& ',\n",
    "    \"{:.1f}\".format(agg_xlsl.est_m),\n",
    "    '& ', \"{:.5f}\".format(agg_xlsl.est_cv),\n",
    "    '& ', \"{:.5f}\".format(agg_xlsl.est_skew),\n",
    "    '\\\\\\\\'\n",
    "    ]\n",
    "outputtxt.append(' '.join(txt))\n",
    "\n",
    "# export results\n",
    "if explort_flag:\n",
    "    pd.DataFrame(data = outputtxt, columns=['text']).to_csv(localpath + 'aggregate_comparison.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
